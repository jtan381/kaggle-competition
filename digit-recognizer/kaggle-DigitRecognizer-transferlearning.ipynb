{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from IPython.core.interactiveshell import InteractiveShell\n# InteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# Read training data from csv file.\ntrain_data_path = '/kaggle/input/digit-recognizer/train.csv'\ntrain_data = pd.read_csv(train_data_path)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = train_data[['label']]\ntrain_labels.head()\nindex = dict()\n\nfor label in train_labels.label.unique():\n    index[label] = train_labels.loc[train_labels['label'] == label].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect the number of data in each class\ncount_of_each_label = train_labels.label.value_counts(sort=False)\nprint(count_of_each_label)\ncount_of_each_label.plot(kind=\"bar\", rot=0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create train and val set, 80-20 ratio for each class\nfrom sklearn.model_selection import train_test_split\n\ntrain_index = []\nval_index = []\nfor label in train_labels.label.unique():\n    train, val = train_test_split(index[label], train_size=0.8, shuffle=True, random_state=42)\n    train_index = [*train_index, *train]\n    val_index = [*val_index, *val]\n    \ntrain_X = train_data.iloc[train_index].drop(columns=['label'])\ntrain_y = train_data.iloc[train_index][['label']]\nval_X = train_data.iloc[val_index].drop(columns=['label'])\nval_y = train_data.iloc[val_index][['label']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take all the value for reshaping -1, dimension (28,28), colour 1\ntrain_X = train_X.values.reshape(-1,28,28)\nval_X = val_X.values.reshape(-1,28,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\n\nplt.imshow(train_X[3], cmap='gray');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transfer Learning requirement\n# Convert to 3 channel images RGB\ntrain_X = np.repeat(train_X[..., np.newaxis], 3, -1)\nval_X = np.repeat(val_X[..., np.newaxis], 3, -1)\nprint(train_X.shape)\n# train_X = np.expand_dims(train_X, axis=-1)\n# val_X = np.expand_dims(val_X, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resize into 32,32 images\ntrain_X = tf.image.resize(train_X, [32, 32], method='nearest')\nval_X = tf.image.resize(val_X, [32, 32], method='nearest')\nprint(train_X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rotation_range=5, width_shift_range=0.1,height_shift_range=0.2, zoom_range=0.1)\ntrain_datagen.fit(train_X, seed=42)\ntrain_tranformed = train_datagen.flow(train_X, train_y, batch_size=32)\n\nval_datagen = ImageDataGenerator()\nval_datagen.fit(val_X, seed=42)\nval_tranformed = val_datagen.flow(val_X, val_y, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tranformed.next()[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4, 4, figsize=(15, 15))\nfor row in range(4):\n    for col in range(4):\n        # generate batch of images\n        batch = train_tranformed.next()\n        # convert to unsigned integers for viewing\n        image = batch[0].astype('uint8')\n        # plot raw pixel data\n        ax[row, col].imshow(np.squeeze(image[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create layers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport datetime\n\ndef create_model(image_shape):\n    base_model = tf.keras.applications.VGG16(include_top=False, pooling='avg', input_shape=image_shape, weights='/kaggle/input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n    # Flatten the CNN\n    base_output = base_model.output\n    flatten = tf.keras.layers.Flatten()(base_output)\n\n    # Dense layer\n    dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten)\n    dense2 = tf.keras.layers.Dense(64, activation='relu')(dense1)\n    output = tf.keras.layers.Dense(10, activation='softmax')(dense2)\n\n    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n\n    # Freeze all base layers\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(\n        loss='sparse_categorical_crossentropy',\n        optimizer=tf.keras.optimizers.Adam(0.001),\n        metrics=['accuracy'],\n    )\n    return model\n\nsave_model_name = datetime.datetime.now()\ncheckpoint1 = ModelCheckpoint(\"{}.h5\".format(save_model_name), monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint1]\n\ninput_shape = train_tranformed.next()[0].shape[1:]\nmodel = create_model(input_shape)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=train_tranformed, steps_per_epoch=len(train_X) / 32, \n                    validation_data=val_tranformed, validation_steps=len(val_X) / 32,\n                    epochs=30, callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recreate the exact same model, including its weights and the optimizer\nnew_model = tf.keras.models.load_model('{}.h5'.format(save_model_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in the test features.\ntest_data_path = '/kaggle/input/digit-recognizer/test.csv'\ntest_data = pd.read_csv(test_data_path)\n# test_data.head()\ntest_data = test_data.values.reshape(-1,28,28)\ntest_data = np.repeat(test_data[..., np.newaxis], 3, -1)\ntest_data = tf.image.resize(test_data, [32, 32], method='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the all the test features.\ntest_probs = new_model.predict(test_data)\ntest_labels = test_probs.argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate Submission File.\nsubmission_df = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\nsubmission_df.Label = test_labels\nsubmission_df.to_csv(\"output.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/c/digit-recognizer","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}